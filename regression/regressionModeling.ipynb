{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data modeling #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Libraries\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import tensorflow\n",
    "warnings.filterwarnings('ignore')\n",
    "#Feature selection\n",
    "from sklearn.feature_selection import RFE\n",
    "import time\n",
    "\n",
    "#Lineal regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#Ridge\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "#Decission trees\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "#Random forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "#Support Vector Machine (SVR)\n",
    "from sklearn.svm import SVR\n",
    "#Neural Nets\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from keras.optimizers import SGD, Adam\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "#XGboost\n",
    "import xgboost as xgb\n",
    "\n",
    "#Performance metrics\n",
    "from sklearn.metrics import mean_squared_error, make_scorer, mean_absolute_error, r2_score,accuracy_score\n",
    "\n",
    "#Cross validation and train-test split\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict, KFold\n",
    "\n",
    "#Grid Search\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)  # For Pandas version < 1.0.0, use -1 instead of None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleanedData.csv')\n",
    "df = df[df.columns[1:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(5, input_shape=(2,), activation='tanh'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    return model\n",
    "\n",
    "tensorflow.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Models\n",
    "\n",
    "lr = {\"name\":\"Linear Regression\",\n",
    "      \"object\": LinearRegression(),\n",
    "      \"paramsGrid\": {},\n",
    "      \"requires_feature_selection\": True,\n",
    "      \"requires_scalling\":True,\n",
    "      \"needs_outliers_handling\":True\n",
    "}\n",
    "\n",
    "rf = {\"name\":\"Random Forest\",\n",
    "      \"object\": RandomForestRegressor(criterion='squared_error',\n",
    "                               min_samples_leaf=3,\n",
    "                               bootstrap=True,\n",
    "                               oob_score=False,\n",
    "                               random_state=seed,\n",
    "                               verbose=0),\n",
    "      \"paramsGrid\": {'max_depth': [3,3.5,4,4.5], 'min_samples_split': [3.5,4,4.5,5],'n_estimators': [300,500,800]},\n",
    "      \"requires_feature_selection\": True,\n",
    "      \"requires_scalling\":True,\n",
    "      \"needs_outliers_handling\":True\n",
    "}\n",
    "\n",
    "ridge = {\"name\":\"Ridge\",\n",
    "      \"object\": Ridge(),\n",
    "      \"paramsGrid\": {'alpha':[10,20,29,29,30,31,32,33,35,40,45,50]},\n",
    "      \"requires_feature_selection\": True,\n",
    "      \"requires_scalling\":True,\n",
    "      \"needs_outliers_handling\":True\n",
    "}\n",
    "\n",
    "lasso = {\"name\":\"Lasso\",\n",
    "      \"object\": Lasso(max_iter=10000),\n",
    "      \"paramsGrid\": {'alpha':[1e-4,1e-3,1e-2,1,5,10,20,30,35]},\n",
    "      \"requires_feature_selection\": False,\n",
    "      \"requires_scalling\":True,\n",
    "      \"needs_outliers_handling\":True\n",
    "}\n",
    "\n",
    "svr = {\n",
    "    \"name\": \"Support Vector Regressor\",\n",
    "    \"object\": SVR(),\n",
    "    \"paramsGrid\": [{'kernel': ['rbf'], 'gamma': [.0009,.001,.005],'C': [1500,2900,4000]},{'kernel': ['linear'], 'C': [1, 10, 100, 1000]}],\n",
    "    \"requires_feature_selection\": True,\n",
    "    \"requires_scalling\": True,\n",
    "    \"needs_outliers_handling\": True\n",
    "}\n",
    "\n",
    "\n",
    "boost = {\"name\":\"XGBoost\",\n",
    "      \"object\": xgb.XGBRegressor(objective='reg:squarederror', seed=seed),\n",
    "      \"paramsGrid\": {'colsample_bytree': [0.1,0.3,0.5], 'n_estimators':[10,15,17,20], 'max_depth': [2,3,4,5]}, \n",
    "      \"requires_feature_selection\": True,\n",
    "      \"requires_scalling\":True,\n",
    "      \"needs_outliers_handling\":True\n",
    "}\n",
    "\n",
    "nn = { \"name\": \"Neural Net\",\n",
    "    \"object\": KerasRegressor(model=create_model, loss='mean_squared_error',\n",
    "                        optimizer=tensorflow.keras.optimizers.legacy.SGD,\n",
    "                          epochs=100, batch_size=10, verbose=0),\n",
    "    \"paramsGrid\": {\"learning_rate\": [0.1, 0.05, 0.01], \"momentum\": [0.8, 0.6, 0.4]},\n",
    "    \"requires_feature_selection\": False,\n",
    "    \"requires_scalling\": True,\n",
    "    \"needs_outliers_handling\": True\n",
    "}\n",
    "\n",
    "models = [nn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modeling(df,modelDict,seed=1,threshold_for_selection=.3,test_size=.3,cv_splits=5):\n",
    "    \n",
    "    #Feature selection\n",
    "    if modelDict[\"requires_feature_selection\"] == True:\n",
    "        corr = df.corr()[\"ViolentCrimesPerPop\"].sort_values(ascending=False)\n",
    "        #Creates a new dataframe with the selected columns\n",
    "        df = df[corr[corr > threshold_for_selection].index] \n",
    "    \n",
    "    #X and Y\n",
    "    X = df.drop('ViolentCrimesPerPop', axis=1)\n",
    "    Y = df['ViolentCrimesPerPop']\n",
    "\n",
    "   \n",
    "\n",
    "    #Train-test split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=test_size,random_state=seed)\n",
    "\n",
    "    #Kfold object\n",
    "    kfold = KFold(n_splits=cv_splits, random_state=seed, shuffle=True)\n",
    "\n",
    "    #Grid Search\n",
    "    gridSearch = GridSearchCV(estimator=modelDict[\"object\"],param_grid=modelDict[\"paramsGrid\"],cv=kfold,scoring=\"r2\") #If grid search is empty it doesn't do CV, just kfolds\n",
    "    gridSearch.fit(X_train, y_train)\n",
    "\n",
    "    #Getting best model\n",
    "    bestModel = gridSearch.best_estimator_\n",
    "\n",
    "    #Predictions \n",
    "    y_pred = bestModel.predict(X_test)\n",
    "    \n",
    "\n",
    "    return [modelDict['name'],mean_squared_error(y_test, y_pred),mean_absolute_error(y_test, y_pred),r2_score(y_test, y_pred),gridSearch.best_params_,bestModel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making Neural Net model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid parameter learning_rate for estimator KerasRegressor.\nThis issue can likely be resolved by setting this parameter in the KerasRegressor constructor:\n`KerasRegressor(learning_rate=0.1)`\nCheck the list of available parameters with `estimator.get_params().keys()`",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/octavioperezurbina/Documents/iteso/Laboratorio de modelado/data-modelling-proyect/regression/regressionModeling.ipynb Cell 9\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mMaking \u001b[39m\u001b[39m{\u001b[39;00mmodel[\u001b[39m\"\u001b[39m\u001b[39mname\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m model...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m row \u001b[39m=\u001b[39m modeling(df,modelDict\u001b[39m=\u001b[39mmodel)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m end \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m delta \u001b[39m=\u001b[39m \u001b[39mround\u001b[39m(end\u001b[39m-\u001b[39mstart,\u001b[39m3\u001b[39m)\n",
      "\u001b[1;32m/Users/octavioperezurbina/Documents/iteso/Laboratorio de modelado/data-modelling-proyect/regression/regressionModeling.ipynb Cell 9\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m#Grid Search\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m gridSearch \u001b[39m=\u001b[39m GridSearchCV(estimator\u001b[39m=\u001b[39mmodelDict[\u001b[39m\"\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m\"\u001b[39m],param_grid\u001b[39m=\u001b[39mmodelDict[\u001b[39m\"\u001b[39m\u001b[39mparamsGrid\u001b[39m\u001b[39m\"\u001b[39m],cv\u001b[39m=\u001b[39mkfold,scoring\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mr2\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m#If grid search is empty it doesn't do CV, just kfolds\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m gridSearch\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m#Getting best model\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/octavioperezurbina/Documents/iteso/Laboratorio%20de%20modelado/data-modelling-proyect/regression/regressionModeling.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m bestModel \u001b[39m=\u001b[39m gridSearch\u001b[39m.\u001b[39mbest_estimator_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_search(evaluate_candidates)\n\u001b[1;32m    900\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_grid))\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:845\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    838\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    839\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    840\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    841\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    842\u001b[0m         )\n\u001b[1;32m    843\u001b[0m     )\n\u001b[0;32m--> 845\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    846\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    847\u001b[0m         clone(base_estimator),\n\u001b[1;32m    848\u001b[0m         X,\n\u001b[1;32m    849\u001b[0m         y,\n\u001b[1;32m    850\u001b[0m         train\u001b[39m=\u001b[39mtrain,\n\u001b[1;32m    851\u001b[0m         test\u001b[39m=\u001b[39mtest,\n\u001b[1;32m    852\u001b[0m         parameters\u001b[39m=\u001b[39mparameters,\n\u001b[1;32m    853\u001b[0m         split_progress\u001b[39m=\u001b[39m(split_idx, n_splits),\n\u001b[1;32m    854\u001b[0m         candidate_progress\u001b[39m=\u001b[39m(cand_idx, n_candidates),\n\u001b[1;32m    855\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_and_score_kwargs,\n\u001b[1;32m    856\u001b[0m     )\n\u001b[1;32m    857\u001b[0m     \u001b[39mfor\u001b[39;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;00m product(\n\u001b[1;32m    858\u001b[0m         \u001b[39menumerate\u001b[39m(candidate_params), \u001b[39menumerate\u001b[39m(cv\u001b[39m.\u001b[39msplit(X, y, groups))\n\u001b[1;32m    859\u001b[0m     )\n\u001b[1;32m    860\u001b[0m )\n\u001b[1;32m    862\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    863\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    864\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    865\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    866\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    867\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     60\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     61\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     63\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     64\u001b[0m )\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m(iterable_with_config)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:1085\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1076\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1077\u001b[0m     \u001b[39m# Only set self._iterating to True if at least a batch\u001b[39;00m\n\u001b[1;32m   1078\u001b[0m     \u001b[39m# was dispatched. In particular this covers the edge\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1082\u001b[0m     \u001b[39m# was very quick and its callback already dispatched all the\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m     \u001b[39m# remaining jobs.\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1085\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n\u001b[1;32m   1086\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterating \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_original_iterator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch_one_batch(iterator):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:901\u001b[0m, in \u001b[0;36mParallel.dispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    900\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 901\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dispatch(tasks)\n\u001b[1;32m    902\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:819\u001b[0m, in \u001b[0;36mParallel._dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    818\u001b[0m     job_idx \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs)\n\u001b[0;32m--> 819\u001b[0m     job \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend\u001b[39m.\u001b[39mapply_async(batch, callback\u001b[39m=\u001b[39mcb)\n\u001b[1;32m    820\u001b[0m     \u001b[39m# A job can complete so quickly than its callback is\u001b[39;00m\n\u001b[1;32m    821\u001b[0m     \u001b[39m# called before we get here, causing self._jobs to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m     \u001b[39m# grow. To ensure correct results ordering, .insert is\u001b[39;00m\n\u001b[1;32m    823\u001b[0m     \u001b[39m# used (rather than .append) in the following line\u001b[39;00m\n\u001b[1;32m    824\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jobs\u001b[39m.\u001b[39minsert(job_idx, job)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:208\u001b[0m, in \u001b[0;36mSequentialBackend.apply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_async\u001b[39m(\u001b[39mself\u001b[39m, func, callback\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    207\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Schedule a func to be run\"\"\"\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     result \u001b[39m=\u001b[39m ImmediateResult(func)\n\u001b[1;32m    209\u001b[0m     \u001b[39mif\u001b[39;00m callback:\n\u001b[1;32m    210\u001b[0m         callback(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/_parallel_backends.py:597\u001b[0m, in \u001b[0;36mImmediateResult.__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, batch):\n\u001b[1;32m    595\u001b[0m     \u001b[39m# Don't delay the application, to avoid keeping the input\u001b[39;00m\n\u001b[1;32m    596\u001b[0m     \u001b[39m# arguments in memory\u001b[39;00m\n\u001b[0;32m--> 597\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresults \u001b[39m=\u001b[39m batch()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36mBatchedCalls.__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/parallel.py:288\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    285\u001b[0m     \u001b[39m# Set the default nested backend to self._backend but do not set the\u001b[39;00m\n\u001b[1;32m    286\u001b[0m     \u001b[39m# change the default number of processes to -1\u001b[39;00m\n\u001b[1;32m    287\u001b[0m     \u001b[39mwith\u001b[39;00m parallel_backend(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backend, n_jobs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_jobs):\n\u001b[0;32m--> 288\u001b[0m         \u001b[39mreturn\u001b[39;00m [func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    289\u001b[0m                 \u001b[39mfor\u001b[39;00m func, args, kwargs \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitems]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/utils/parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    126\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 127\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:720\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m parameters\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    718\u001b[0m         cloned_parameters[k] \u001b[39m=\u001b[39m clone(v, safe\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m--> 720\u001b[0m     estimator \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcloned_parameters)\n\u001b[1;32m    722\u001b[0m start_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    724\u001b[0m X_train, y_train \u001b[39m=\u001b[39m _safe_split(estimator, X, y, train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/scikeras/wrappers.py:1165\u001b[0m, in \u001b[0;36mBaseWrapper.set_params\u001b[0;34m(self, **params)\u001b[0m\n\u001b[1;32m   1161\u001b[0m             \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mset_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m{param: value})\n\u001b[1;32m   1162\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m   1163\u001b[0m             \u001b[39m# Give a SciKeras specific user message to aid\u001b[39;00m\n\u001b[1;32m   1164\u001b[0m             \u001b[39m# in moving from the Keras wrappers\u001b[39;00m\n\u001b[0;32m-> 1165\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1166\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid parameter \u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m for estimator \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1167\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mThis issue can likely be resolved by setting this parameter\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1168\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in the \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m constructor:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1169\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m`\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00mparam\u001b[39m}\u001b[39;00m\u001b[39m=\u001b[39m\u001b[39m{\u001b[39;00mvalue\u001b[39m}\u001b[39;00m\u001b[39m)`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1170\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mCheck the list of available parameters with\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1171\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m `estimator.get_params().keys()`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1172\u001b[0m             ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid parameter learning_rate for estimator KerasRegressor.\nThis issue can likely be resolved by setting this parameter in the KerasRegressor constructor:\n`KerasRegressor(learning_rate=0.1)`\nCheck the list of available parameters with `estimator.get_params().keys()`"
     ]
    }
   ],
   "source": [
    "#Main\n",
    "\n",
    "results = pd.DataFrame(columns=['model','mse', 'mae', 'r2','hiperparameters','modelObject'])\n",
    "times = []\n",
    "for model in models:\n",
    "    print(f'Making {model[\"name\"]} model...')\n",
    "    start = time.time()\n",
    "    row = modeling(df,modelDict=model)\n",
    "\n",
    "    end = time.time()\n",
    "    delta = round(end-start,3)\n",
    "    times.append(delta)\n",
    "\n",
    "    results.loc[len(results)] = row\n",
    "\n",
    "results[\"duration\"] = times\n",
    "\n",
    "results[[col for col in results.columns if col != \"modelObject\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
